{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.11.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Natural Language Processing (NLP)\n",
    "\n",
    "Natural Language Processing (NLP) is a subfield of computer science and artificial intelligence (AI) that leverages machine learning to enable computers to understand and communicate using human language. By combining computational linguistics—the rule-based modeling of human language—with statistical modeling, machine learning (ML), and deep learning, NLP allows computers and digital devices to recognize, understand, and generate text and speech.\n",
    "\n",
    "NLP research has paved the way for the era of generative AI, enhancing the communication skills of large language models (LLMs) and enabling image generation models to understand requests. NLP is integral to everyday technologies such as search engines, customer service chatbots, voice-operated GPS systems, and digital assistants on smartphones. It also plays a growing role in enterprise solutions, streamlining business operations, increasing employee productivity, and simplifying mission-critical processes.\n",
    "\n",
    "## Benefits of NLP\n",
    "\n",
    "A natural language processing system, once properly trained, can perform tasks rapidly and efficiently, freeing staff for more productive work. Some key benefits include:\n",
    "\n",
    "- **Faster Insight Discovery:** NLP enables organizations to find hidden patterns, trends, and relationships within content, supporting deeper insights and better-informed decision-making, and surfacing new business ideas.\n",
    "- **Greater Budget Savings:** With the massive volume of unstructured text data available, NLP automates the gathering, processing, and organization of information, reducing manual effort.\n",
    "- **Quick Access to Corporate Data:** Enterprises can build a knowledge base of organizational information that can be efficiently accessed with AI search, enhancing customer service and sales efforts.\n",
    "\n",
    "## Challenges of NLP\n",
    "\n",
    "Despite its benefits, NLP models face several challenges:\n",
    "\n",
    "- **Biased Training:** Biased data used in training can skew results. This risk is amplified in diverse applications such as government services, healthcare, and HR interactions.\n",
    "- **Misinterpretation:** NLP solutions can struggle with obscure dialects, slang, homonyms, incorrect grammar, and background noise, leading to errors.\n",
    "- **New Vocabulary:** Continuous evolution of language with new words and changing grammar conventions can challenge NLP systems.\n",
    "- **Tone of Voice:** Sarcasm, stress, and body language can alter the meaning of words, complicating semantic analysis.\n",
    "\n",
    "Human language's inherent ambiguities make it challenging to develop software that accurately interprets text or voice data. Programmers must teach NLP applications to recognize and understand these irregularities to ensure accuracy and usefulness.\n",
    "\n",
    "## How NLP Works\n",
    "\n",
    "NLP combines computational linguistics with machine learning algorithms and deep learning. Computational linguistics uses data science to analyze language and speech through syntactical and semantical analysis:\n",
    "\n",
    "- **Syntactical Analysis:** Determines the meaning of words, phrases, or sentences by parsing syntax and applying grammar rules.\n",
    "- **Semantical Analysis:** Uses syntactic output to draw and interpret meaning within sentence structures.\n",
    "\n",
    "Parsing can take two forms:\n",
    "\n",
    "- **Dependency Parsing:** Looks at relationships between words.\n",
    "- **Constituency Parsing:** Builds a parse tree representing the syntactic structure of sentences.\n",
    "\n",
    "Self-supervised learning (SSL) supports NLP by using large amounts of labeled data to train AI models, replacing some or all manually labeled training data.\n",
    "\n",
    "## Approaches to NLP\n",
    "\n",
    "There are three main approaches to NLP:\n",
    "\n",
    "- **Rules-Based NLP:** Uses preprogrammed rules to provide specific responses, limited in scope and scalability.\n",
    "- **Statistical NLP:** Automatically extracts, classifies, and labels text and voice data elements, assigning statistical likelihoods to meanings. It introduced techniques like part-of-speech tagging and informed early developments like spellcheckers.\n",
    "- **Deep Learning NLP:** Uses neural network models to analyze large volumes of unstructured data, enhancing accuracy. Subcategories include:\n",
    "  - **Sequence-to-Sequence (seq2seq) Models:** Used for machine translation.\n",
    "  - **Transformer Models:** Use tokenization and self-attention for efficient training on massive text databases.\n",
    "  - **Autoregressive Models:** Predict the next word in a sequence, enabling text generation.\n",
    "  - **Foundation Models:** Prebuilt models like IBM Granite™ support NLP tasks such as content generation and insight extraction.\n",
    "\n",
    "## NLP Tasks\n",
    "\n",
    "Several tasks help process human text and voice data:\n",
    "\n",
    "- **Coreference Resolution:** Identifies if two words refer to the same entity.\n",
    "- **Named Entity Recognition (NER):** Identifies useful entities like names or locations.\n",
    "- **Part-of-Speech Tagging:** Determines the part of speech of words based on context.\n",
    "- **Word Sense Disambiguation:** Selects the meaning of words with multiple meanings.\n",
    "- **Speech Recognition:** Converts voice data into text.\n",
    "- **Natural Language Generation (NLG):** Converts structured information into conversational language.\n",
    "- **Natural Language Understanding (NLU):** Analyzes sentence meaning.\n",
    "- **Sentiment Analysis:** Extracts subjective qualities like attitudes and emotions.\n",
    "\n",
    "# Lexicons\n",
    "\n",
    "Lexicons are comprehensive collections of words and their meanings, often including additional linguistic information such as pronunciation, part of speech, etymology, and usage examples. In the context of natural language processing (NLP) and computational linguistics, a lexicon typically serves as a crucial resource for various language processing tasks.\n",
    "\n",
    "## Types of Lexicons\n",
    "\n",
    "- **General Lexicons:** These contain words and their definitions, much like a traditional dictionary. They provide general language knowledge that can be applied to a wide range of NLP tasks.\n",
    "  - **Example:** WordNet, which groups English words into sets of synonyms and provides short definitions and usage examples.\n",
    "- **Domain-Specific Lexicons:** These are tailored to specific fields or industries, containing terminology and jargon unique to those areas.\n",
    "  - **Example:** A medical lexicon that includes terms like \"cardiomyopathy,\" \"angioplasty,\" etc.\n",
    "- **Sentiment Lexicons:** These contain words and phrases annotated with their sentiment polarity (positive, negative, neutral) and sometimes their intensity.\n",
    "  - **Example:** SentiWordNet, which assigns sentiment scores to synsets (sets of cognitive synonyms) in WordNet.\n",
    "- **Morphological Lexicons:** These focus on the structure of words, providing information about their root forms, prefixes, suffixes, and inflections.\n",
    "  - **Example:** CELEX Lexical Database, which includes morphological, syntactic, and phonological information for English, Dutch, and German.\n",
    "- **Multilingual Lexicons:** These lexicons support multiple languages, providing translations and linguistic information across languages.\n",
    "  - **Example:** BabelNet, a multilingual semantic network that includes lexicons in many different languages.\n",
    "\n",
    "## Applications of Lexicons in NLP\n",
    "\n",
    "- **Word Sense Disambiguation:** Lexicons help determine the correct meaning of a word based on context.\n",
    "- **Part-of-Speech Tagging:** Lexicons provide information on the grammatical categories of words, aiding in syntactic analysis.\n",
    "- **Named Entity Recognition (NER):** Domain-specific lexicons enhance the identification and classification of proper nouns.\n",
    "- **Sentiment Analysis:** Sentiment lexicons are used to identify and evaluate the sentiment expressed in text.\n",
    "- **Language Translation:** Multilingual lexicons support the accurate translation of words and phrases between languages.\n",
    "- **Text-to-Speech and Speech-to-Text Systems:** Lexicons provide pronunciation guides and phonetic information.\n",
    "\n",
    "## Example: WordNet\n",
    "\n",
    "WordNet is one of the most widely used lexicons in NLP. It groups English words into sets of synonyms called synsets, provides short definitions, and includes usage examples. Additionally, it captures various semantic relationships between synsets, such as hypernyms (general terms), hyponyms (specific terms), and meronyms (part-whole relationships).\n",
    "\n",
    "## Importance of Lexicons\n",
    "\n",
    "Lexicons are fundamental to many NLP tasks because they provide the necessary linguistic knowledge to understand and process human language. They help bridge the gap between raw text data and meaningful, structured information, enabling more accurate and effective language models and applications.\n",
    "\n",
    "# Tokenization in NLP\n",
    "\n",
    "Tokenization is a crucial preprocessing step in natural language processing (NLP) that involves breaking down text into smaller units called tokens. These tokens can be words, subwords, or even characters, depending on the level of granularity required for the specific NLP task. Tokenization is essential for converting raw text into a format that can be easily analyzed and processed by machine learning models.\n",
    "\n",
    "## Types of Tokenization\n",
    "\n",
    "1. **Word Tokenization:** Splits text into individual words. This is the most common form of tokenization.\n",
    "   - **Example:** \"Natural language processing is fascinating.\" → [\"Natural\", \"language\", \"processing\", \"is\", \"fascinating\", \".\"]\n",
    "\n",
    "2. **Subword Tokenization:** Breaks down words into smaller units, which can be useful for handling rare or out-of-vocabulary words. This is often used in neural network-based models.\n",
    "   - **Example:** \"unhappiness\" → [\"un\", \"happiness\"]\n",
    "\n",
    "3. **Character Tokenization:** Splits text into individual characters. This can be useful for tasks that require a high level of granularity.\n",
    "   - **Example:** \"Hello\" → [\"H\", \"e\", \"l\", \"l\", \"o\"]\n",
    "\n",
    "4. **Sentence Tokenization:** Divides text into individual sentences. This is useful for tasks that require sentence-level analysis.\n",
    "   - **Example:** \"Hello world! How are you?\" → [\"Hello world!\", \"How are you?\"]\n",
    "\n",
    "## Methods of Tokenization\n",
    "\n",
    "1. **Rule-Based Tokenization:** Uses predefined rules to split text. This method is simple and fast but can struggle with edge cases such as contractions and punctuation.\n",
    "   - **Example:** Splitting on spaces and punctuation marks.\n",
    "\n",
    "2. **Statistical Tokenization:** Uses probabilistic models to determine token boundaries. This method can handle more complex cases but requires a training phase.\n",
    "   - **Example:** Hidden Markov Models (HMMs) or Conditional Random Fields (CRFs).\n",
    "\n",
    "3. **Subword Tokenization Algorithms:** These include methods like Byte Pair Encoding (BPE) and WordPiece, which are commonly used in transformer models.\n",
    "   - **Byte Pair Encoding (BPE):** Iteratively merges the most frequent pairs of characters or character sequences.\n",
    "   - **WordPiece:** Similar to BPE, but optimized for use in models like BERT.\n",
    "\n",
    "## Challenges in Tokenization\n",
    "\n",
    "- **Ambiguity:** Some languages, like Chinese or Japanese, do not use spaces to separate words, making tokenization more challenging.\n",
    "- **Punctuation:** Handling punctuation marks appropriately can be tricky, as they can serve different purposes in different contexts.\n",
    "- **Contractions and Compound Words:** Dealing with contractions (e.g., \"don't\") and compound words (e.g., \"mother-in-law\") can be complex.\n",
    "- **Special Characters and Emojis:** Modern text, especially from social media, includes emojis and special characters that need careful handling.\n",
    "\n",
    "## Importance of Tokenization\n",
    "\n",
    "Tokenization is a foundational step in NLP that influences the performance of subsequent tasks such as:\n",
    "\n",
    "- **Text Classification:** Breaking text into tokens allows for the creation of feature vectors that can be used in classification models.\n",
    "- **Named Entity Recognition (NER):** Identifying entities within a tokenized text.\n",
    "- **Machine Translation:** Translating text from one language to another often starts with tokenizing the input text.\n",
    "- **Sentiment Analysis:** Analyzing the sentiment of text requires understanding the meaning and context of individual tokens.\n",
    "\n",
    "## Example: Tokenization with NLTK\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = \"Natural language processing is fascinating. Let's learn more about it!\"\n",
    "\n",
    "# Word Tokenization\n",
    "word_tokens = word_tokenize(text)\n",
    "print(word_tokens)\n",
    "# Output: ['Natural', 'language', 'processing', 'is', 'fascinating', '.', 'Let', \"'s\", 'learn', 'more', 'about', 'it', '!']\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentence_tokens = sent_tokenize(text)\n",
    "print(sentence_tokens)\n",
    "# Output: ['Natural language processing is fascinating.', \"Let's learn more about it!\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization in NLP\n",
    "\n",
    "## Stemming\n",
    "\n",
    "Stemming is a text normalization technique in natural language processing (NLP) that reduces words to their root or base form. The primary goal of stemming is to group together different forms of the same word so they can be analyzed as a single item. Stemming algorithms, often called \"stemmers,\" perform this process by stripping prefixes or suffixes from words.\n",
    "\n",
    "### Example:\n",
    "- **Words:** \"running,\" \"runner,\" \"ran\"\n",
    "- **Stemmed Form:** \"run\"\n",
    "\n",
    "### Popular Stemming Algorithms:\n",
    "1. **Porter Stemmer:** One of the most widely used stemming algorithms, known for its simplicity and effectiveness.\n",
    "2. **Snowball Stemmer:** An improved version of the Porter Stemmer with better handling of various linguistic exceptions.\n",
    "3. **Lancaster Stemmer:** An aggressive stemmer that can produce shorter stems but may sometimes lead to over-stemming.\n",
    "\n",
    "### Advantages:\n",
    "- **Speed:** Stemming algorithms are usually fast and efficient.\n",
    "- **Simplicity:** Easy to implement and understand.\n",
    "\n",
    "### Disadvantages:\n",
    "- **Accuracy:** Stemming can be overly aggressive, leading to incorrect root forms (e.g., \"relational\" and \"relation\" both stem to \"relat\").\n",
    "- **Ambiguity:** Different words with the same stem may not be related in meaning.\n",
    "\n",
    "### Example Using NLTK:\n",
    "```python\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "words = [\"python\", \"pythoner\", \"pythoning\", \"pythoned\", \"pythonly\"]\n",
    "stemmed_words = [ps.stem(word) for word in words]\n",
    "print(stemmed_words)\n",
    "# Output: ['python', 'python', 'python', 'python', 'pythonly']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization in NLP\n",
    "\n",
    "Lemmatization is another text normalization technique in NLP that reduces words to their base or dictionary form, known as the lemma. Unlike stemming, lemmatization considers the context and morphological analysis of the word. This means it looks at the intended meaning and part of speech (POS) to ensure the base form is correct.\n",
    "\n",
    "## Example:\n",
    "- **Words:** \"running,\" \"ran\"\n",
    "- **Lemmatized Form:** \"run\"\n",
    "\n",
    "## Lemmatization Algorithms:\n",
    "- **WordNet Lemmatizer:** A common lemmatizer that uses the WordNet lexical database.\n",
    "- **spaCy Lemmatizer:** Part of the spaCy NLP library, which provides advanced lemmatization capabilities.\n",
    "\n",
    "## Advantages:\n",
    "- **Accuracy:** Produces more accurate base forms by considering the word's meaning and context.\n",
    "- **Context-Awareness:** Differentiates between words with different meanings and parts of speech.\n",
    "\n",
    "## Disadvantages:\n",
    "- **Complexity:** More computationally intensive and slower than stemming.\n",
    "- **Dependency:** Requires a comprehensive dictionary or database for accurate results.\n",
    "\n",
    "## Example Using NLTK:\n",
    "```python\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "words = [\"running\", \"ran\", \"runner\"]\n",
    "lemmatized_words = [wnl.lemmatize(word, pos='v') for word in words]\n",
    "print(lemmatized_words)\n",
    "# Output: ['run', 'run', 'runner']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "## Stemming:\n",
    "- Fast and easy to implement.\n",
    "- Less accurate, may produce non-dictionary words.\n",
    "- Suitable for applications where speed is crucial, and precision is less important.\n",
    "\n",
    "## Lemmatization:\n",
    "- More accurate, producing dictionary words.\n",
    "- Considers word context and part of speech.\n",
    "- Suitable for applications where accuracy and meaning are important, even if it is slower.\n",
    "\n",
    "\n",
    "In summary, stemming and lemmatization are essential techniques in NLP for text normalization. \n",
    "Stemming is faster but less accurate, while lemmatization is slower but more precise. \n",
    "The choice between the two depends on the specific requirements of the NLP task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech (POS) Tagging in NLP\n",
    "\n",
    "Part-of-Speech (POS) tagging is a crucial step in natural language processing (NLP) that involves assigning a part of speech to each word in a given text. The parts of speech include nouns, verbs, adjectives, adverbs, pronouns, prepositions, conjunctions, and interjections. POS tagging helps in understanding the syntactic structure of a sentence and is fundamental for various NLP tasks such as parsing, named entity recognition, and machine translation.\n",
    "\n",
    "## Importance of POS Tagging\n",
    "\n",
    "1. **Syntactic Parsing:** POS tags help in identifying the grammatical structure of sentences, which is essential for parsing.\n",
    "2. **Word Sense Disambiguation:** Knowing the POS of a word can help in determining its meaning in a particular context.\n",
    "3. **Named Entity Recognition (NER):** POS tags are used to identify and classify proper nouns within a text.\n",
    "4. **Information Retrieval:** POS tagging enhances search algorithms by understanding the context of words.\n",
    "\n",
    "## Common POS Tags\n",
    "\n",
    "- **Noun (NN):** A person, place, thing, or idea (e.g., cat, city, happiness).\n",
    "- **Verb (VB):** An action or state (e.g., run, is).\n",
    "- **Adjective (JJ):** Describes a noun (e.g., blue, quick).\n",
    "- **Adverb (RB):** Describes a verb, adjective, or other adverb (e.g., quickly, very).\n",
    "- **Pronoun (PRP):** Replaces a noun (e.g., he, she, it).\n",
    "- **Preposition (IN):** Shows relationship between a noun (or pronoun) and other words (e.g., in, on, at).\n",
    "- **Conjunction (CC):** Connects words, phrases, or clauses (e.g., and, but).\n",
    "- **Interjection (UH):** Expresses emotion (e.g., oh, wow).\n",
    "\n",
    "## POS Tagging Methods\n",
    "\n",
    "1. **Rule-Based Tagging:** Uses predefined grammatical rules to assign POS tags.\n",
    "   - Example: Assigning tags based on word suffixes.\n",
    "\n",
    "2. **Statistical Tagging:** Uses probabilistic models to predict POS tags based on context.\n",
    "   - Example: Hidden Markov Models (HMMs).\n",
    "\n",
    "3. **Machine Learning Tagging:** Uses supervised learning techniques to train models on labeled data.\n",
    "   - Example: Conditional Random Fields (CRFs) and neural networks.\n",
    "\n",
    "## Example Using NLTK\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "print(pos_tags)\n",
    "# Output: [('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) in NLP\n",
    "\n",
    "Named Entity Recognition (NER) is a crucial task in natural language processing (NLP) that involves identifying and classifying named entities in text into predefined categories such as names of people, organizations, locations, dates, quantities, monetary values, and more. NER helps in extracting meaningful information from text, which is essential for various NLP applications like information retrieval, question answering, and text summarization.\n",
    "\n",
    "## Importance of NER\n",
    "\n",
    "1. **Information Extraction:** NER helps in extracting specific information from large volumes of text, making it easier to find relevant data.\n",
    "2. **Improved Search Engines:** Enhances search algorithms by identifying and categorizing key entities in search queries and documents.\n",
    "3. **Content Recommendation:** Facilitates personalized content recommendations by understanding user preferences through identified entities.\n",
    "4. **Data Organization:** Aids in organizing and structuring unstructured data by categorizing entities.\n",
    "\n",
    "## Common Named Entity Categories\n",
    "\n",
    "- **Person (PER):** Names of individuals (e.g., John Doe, Barack Obama).\n",
    "- **Organization (ORG):** Names of companies, institutions, and organizations (e.g., Google, United Nations).\n",
    "- **Location (LOC):** Names of geographical locations (e.g., Paris, Mount Everest).\n",
    "- **Date (DATE):** Dates and times (e.g., January 1, 2024, 10:00 AM).\n",
    "- **Monetary Value (MONEY):** Monetary values (e.g., $100, €50).\n",
    "- **Percentage (PERCENT):** Percentages (e.g., 50%, 75%).\n",
    "\n",
    "## NER Techniques\n",
    "\n",
    "1. **Rule-Based Systems:** Use predefined patterns and grammatical rules to identify named entities.\n",
    "   - Example: Using regular expressions to identify dates.\n",
    "\n",
    "2. **Machine Learning-Based Systems:** Use supervised learning algorithms to train models on labeled data.\n",
    "   - Example: Conditional Random Fields (CRFs), Hidden Markov Models (HMMs).\n",
    "\n",
    "3. **Deep Learning-Based Systems:** Use neural networks, particularly recurrent neural networks (RNNs) and transformers, for more accurate and context-aware entity recognition.\n",
    "   - Example: Bidirectional LSTM-CRF, BERT-based models.\n",
    "\n",
    "## Example Using NLTK\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "def get_named_entities(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    entities = []\n",
    "    for chunk in chunked:\n",
    "        if isinstance(chunk, Tree):\n",
    "            entity = \" \".join(c[0] for c in chunk)\n",
    "            entity_type = chunk.label()\n",
    "            entities.append((entity, entity_type))\n",
    "    return entities\n",
    "\n",
    "text = \"Barack Obama was born on August 4, 1961, in Honolulu, Hawaii.\"\n",
    "entities = get_named_entities(text)\n",
    "print(entities)\n",
    "# Output: [('Barack Obama', 'PERSON'), ('August 4, 1961', 'DATE'), ('Honolulu', 'GPE'), ('Hawaii', 'GPE')]\n",
    "```\n",
    "\n",
    "## Challenges in NER\n",
    "\n",
    "- **Ambiguity:** Words or phrases can have multiple meanings, making it difficult to correctly identify entities.\n",
    "- **Context:** Understanding the context is crucial for accurate entity recognition, especially in complex sentences.\n",
    "- **Language Variability:** Variations in language, slang, and regional differences can complicate NER.\n",
    "- **Data Sparsity:** Lack of sufficient labeled data for training can impact the performance of NER models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
